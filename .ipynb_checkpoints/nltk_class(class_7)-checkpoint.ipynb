{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Natural Language Processing Toolkit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lots of Applications\n",
    "1) Translation\n",
    "2) Sentiment Analysis\n",
    "3) Topic Modelling\n",
    "4) Document Classification/ Clustering\n",
    "5) Generating new language eg Chatbots\n",
    "6) Word Analgoies\n",
    "7) Question Similarity Detection\n",
    "8) Summarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import shakespeare,brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1161192"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = brown.sents(categories=[\"humor\",\"news\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5676\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "romance_data = brown.sents(categories=[\"romance\"])\n",
    "science_data = brown.sents(categories=[\"science_fiction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4431\n"
     ]
    }
   ],
   "source": [
    "print(len(romance_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "948\n"
     ]
    }
   ],
   "source": [
    "print(len(science_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"This is Machine Learning class going on, \n",
    "        we are learning about algorithms!\"\"\"\n",
    "\n",
    "text2 = \"\"\"JEE Mains was conducted successfully! \n",
    "         10 lac candidates appeared, CBSE to decleare results online\"\"\"\n",
    "\n",
    "review1 = \"The movie was great, I liked it very much\"\n",
    "review2 = \"The movie was okayish, acting was bad\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert Textual Data into Numerical Features\n",
    "#### Steps\n",
    "1. Tokenization -> Sentence & Word Level\n",
    "2.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ramendra/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['JEE Mains was conducted successfully!', '10 lac candidates appeared, CBSE to decleare results online']\n"
     ]
    }
   ],
   "source": [
    "sents = sent_tokenize(text2)\n",
    "\n",
    "print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 lac candidates appeared, CBSE to decleare results online\n"
     ]
    }
   ],
   "source": [
    "print(sents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', 'lac', 'candidates', 'appeared', ',', 'CBSE', 'to', 'decleare', 'results', 'online']\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(sents[1])\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ramendra/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = [w for w in words if w not in sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', 'lac', 'candidates', 'appeared', ',', 'CBSE', 'decleare', 'results', 'online']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lac',\n",
       " 'candidates',\n",
       " 'appeared',\n",
       " 'CBSE',\n",
       " 'to',\n",
       " 'decleare',\n",
       " 'results',\n",
       " 'online']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer('[a-zA-Z]+')\n",
    "tokenizer.tokenize(sents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stopwords = [\"a\",\"an\",\"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Boltz is running very fast, he is faster than others, \n",
    "            probably the fastest guy in the world\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stemming\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer, SnowballStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "ls = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fast'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem(\"fast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'faster'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem(\"faster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fastest'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem(\"fastest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fast'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem(\"fasting\")\n",
    "ls.stem(\"fasting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cri'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem(\"crying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fli'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem(\"flying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fly'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls.stem(\"flying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'greatest'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb = SnowballStemmer(language='english')\n",
    "sb.stem(\"greatest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ramendra/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'greatest'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl.lemmatize(\"greatest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl.lemmatize(\"loving\",'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    text,\n",
    "    text2,\n",
    "    review1,\n",
    "    review2\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Boltz is running very fast, he is faster than others, \\n            probably the fastest guy in the world', 'JEE Mains was conducted successfully! \\n         10 lac candidates appeared, CBSE to decleare results online', 'The movie was great, I liked it very much', 'The movie was okayish, acting was bad']\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "        0, 0, 1, 1, 0, 0, 1],\n",
       "       [0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        1, 1, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(token_pattern='[A-Za-z]+',stop_words=sw,ngram_range=(1,2))\n",
    "cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = \"Movie is good\"\n",
    "cv.transform([test_sentence]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acting',\n",
       " 'acting bad',\n",
       " 'appeared',\n",
       " 'appeared cbse',\n",
       " 'bad',\n",
       " 'boltz',\n",
       " 'boltz running',\n",
       " 'candidates',\n",
       " 'candidates appeared',\n",
       " 'cbse',\n",
       " 'cbse decleare',\n",
       " 'conducted',\n",
       " 'conducted successfully',\n",
       " 'decleare',\n",
       " 'decleare results',\n",
       " 'fast',\n",
       " 'fast faster',\n",
       " 'faster',\n",
       " 'faster others',\n",
       " 'fastest',\n",
       " 'fastest guy',\n",
       " 'great',\n",
       " 'great liked',\n",
       " 'guy',\n",
       " 'guy world',\n",
       " 'jee',\n",
       " 'jee mains',\n",
       " 'lac',\n",
       " 'lac candidates',\n",
       " 'liked',\n",
       " 'liked much',\n",
       " 'mains',\n",
       " 'mains conducted',\n",
       " 'movie',\n",
       " 'movie great',\n",
       " 'movie okayish',\n",
       " 'much',\n",
       " 'okayish',\n",
       " 'okayish acting',\n",
       " 'online',\n",
       " 'others',\n",
       " 'others probably',\n",
       " 'probably',\n",
       " 'probably fastest',\n",
       " 'results',\n",
       " 'results online',\n",
       " 'running',\n",
       " 'running fast',\n",
       " 'successfully',\n",
       " 'successfully lac',\n",
       " 'world']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boltz': 5,\n",
       " 'running': 46,\n",
       " 'fast': 15,\n",
       " 'faster': 17,\n",
       " 'others': 40,\n",
       " 'probably': 42,\n",
       " 'fastest': 19,\n",
       " 'guy': 23,\n",
       " 'world': 50,\n",
       " 'boltz running': 6,\n",
       " 'running fast': 47,\n",
       " 'fast faster': 16,\n",
       " 'faster others': 18,\n",
       " 'others probably': 41,\n",
       " 'probably fastest': 43,\n",
       " 'fastest guy': 20,\n",
       " 'guy world': 24,\n",
       " 'jee': 25,\n",
       " 'mains': 31,\n",
       " 'conducted': 11,\n",
       " 'successfully': 48,\n",
       " 'lac': 27,\n",
       " 'candidates': 7,\n",
       " 'appeared': 2,\n",
       " 'cbse': 9,\n",
       " 'decleare': 13,\n",
       " 'results': 44,\n",
       " 'online': 39,\n",
       " 'jee mains': 26,\n",
       " 'mains conducted': 32,\n",
       " 'conducted successfully': 12,\n",
       " 'successfully lac': 49,\n",
       " 'lac candidates': 28,\n",
       " 'candidates appeared': 8,\n",
       " 'appeared cbse': 3,\n",
       " 'cbse decleare': 10,\n",
       " 'decleare results': 14,\n",
       " 'results online': 45,\n",
       " 'movie': 33,\n",
       " 'great': 21,\n",
       " 'liked': 29,\n",
       " 'much': 36,\n",
       " 'movie great': 34,\n",
       " 'great liked': 22,\n",
       " 'liked much': 30,\n",
       " 'okayish': 37,\n",
       " 'acting': 0,\n",
       " 'bad': 4,\n",
       " 'movie okayish': 35,\n",
       " 'okayish acting': 38,\n",
       " 'acting bad': 1}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.23407438,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.23407438,\n",
       "        0.23407438, 0.23407438, 0.        , 0.23407438, 0.23407438,\n",
       "        0.23407438, 0.46814876, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.23407438, 0.23407438, 0.        , 0.23407438,\n",
       "        0.        , 0.23407438, 0.29881329, 0.        , 0.18454693,\n",
       "        0.        , 0.23407438],\n",
       "       [0.27310368, 0.        , 0.27310368, 0.        , 0.        ,\n",
       "        0.27310368, 0.27310368, 0.27310368, 0.27310368, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.27310368, 0.27310368,\n",
       "        0.        , 0.27310368, 0.        , 0.        , 0.        ,\n",
       "        0.27310368, 0.        , 0.        , 0.27310368, 0.        ,\n",
       "        0.27310368, 0.        , 0.        , 0.27310368, 0.        ,\n",
       "        0.17431854, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.40628908, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.40628908, 0.        , 0.        ,\n",
       "        0.40628908, 0.        , 0.32032298, 0.40628908, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.25932906, 0.        , 0.32032298,\n",
       "        0.25932906, 0.        ],\n",
       "       [0.        , 0.4203817 , 0.        , 0.4203817 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.33143376, 0.        , 0.4203817 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.26832419, 0.        , 0.        ,\n",
       "        0.53664838, 0.        ]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = TfidfVectorizer()\n",
    "tf.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.78528828, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.6191303 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transform([\"cbse movie isn't  good\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
